# 7.10 阅读公众号有感



### 我想学大模型，应该从哪个模型开始？LLaMA生态家谱整理和分析

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/GCNbdU0ticiboPpNZTuiaJwoB47uDruic5Wgr2KtiaPa8IvSziaHX1IZMappB3wGwwtwG638TAIxpBf6dGiaxDMy2aYDQ/640?wx_fmt=jpeg&wxfrom=13&tp=wxpic)

> 图片中分了4个阶段，但是第三个和第四个阶段一般都会放在一起，属于对齐阶段。所以一般会分成如下3个阶段：
>
> - Stage 1: 预训练(Pretrain)
> - Stage 2: 监督微调(SFT)
> - Stage 3: 对齐(Reward Model + RLHF)

太逗了，文章里面说那个监督微调的部分，只是**有钱**和**没钱**之间的差别。有钱可以全参数微调，没钱就只能PEFT了。

------

### 清华最新「持续学习」综述，32页详述持续学习理论、方法与应用综述

> 基于现有的理论和实证结果，将持续学习的一般目标总结为：在资源效率的背景下，确保适当的稳定性-可塑性权衡，以及充分的任务内/任务间泛化能力。

![图片](https://mmbiz.qpic.cn/mmbiz_png/AefvpgiaIPw0tTK9ScgQ2WGFZReNmIWj66qI5bbSRibXyLTicULTMJq3ud2AT5fDQp2SfTuQZiaP6LraZmFeaJBJYw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1&tp=wxpic)

- 数据方面： 经验回放
- 模型方面：基于模型结构的设计（例如模型添加分支、添加参数等等）
- 损失函数方面：添加正则项
- 优化方面：基于显式优化进行



将特殊挑战分为了**场景复杂性**和**任务特殊性**



可以思考一下后面的综述应该以哪篇文章为base? 

*A Comprehensive Survey of Continual LearningTheory, Method and Application*  感觉这篇还挺可以的

***Deep Class-Incremental Learning: A Survey***  是从model centric 和 data centric的角度来分的，其实我更喜欢这种分类法！ 

Recent Advances of Continual Learning in Computer Vision: An Overview （感觉很一般）

Class-incremental learning: survey and performance evaluation

A continual learning survey: Defying forgetting in classification tasks

------

Class-Incremental Learning based on Label Generation



iCaRL的解读文章

[【心理学与AI】iCaRL: Incremental Classifier and Representation Learning - 简书 (jianshu.com)](https://www.jianshu.com/p/66a84f8a3381)

[论文笔记系列--iCaRL： Incremental Classifier and Learning - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/55739596?from_voters_page=true)