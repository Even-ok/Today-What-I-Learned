## pre-train-based

### survey

Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need



### prompt-based

- PromptFusion: Decoupling Stability and Plasticity for Continual Learning
- A Unified Continual Learning Framework with General Parameter-Efficient Tuning
- CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning
- Learning Expressive Prompting With Residuals for Vision Transformers





### Vision-language

- Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Model
- PLOT: Prompt Learning with Optimal Transport for Vision-Language Models

